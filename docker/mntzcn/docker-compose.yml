version: '3'

services:
  hadoop:
    build: ./hadoop
    container_name: hadoop
    networks:
      default:
        aliases:
        - hadoop
    ports:
      - 9000:9000 # hdfs port
      - 8088:8088 # YARN
      - 8042:8042 # YARN JOBS LOG SERVER
      - 19888:19888 # JobTracker
      - 50070:50070 # NameNode
      - 50075:50075 # DataNode
    command: bash -c "chmod +x /etc/bootstrap.sh && sh /etc/bootstrap.sh -d"
    volumes:
      - $PWD/conf/hive-site.xml:/user/oozie/hive-site.xml

  hive:
    build:
      ./hive
    image: hive-shm:1.2.2
    container_name: mntzcn_hive
    ports:
    - "10000:10000"
    volumes:
    - $PWD/conf/hive-site.xml:/opt/hive/conf/hive-site.xml
    - $PWD/container_data/hive/warehouse:/shared_data/hive/warehouse
    #- $PWD/table_data:/shared_data/table_data
#    links:
#    - metastore

#  metastore:
#    build:
#      ./mysql-ms
#    #image: mysql-shm:5.6.38
#    container_name: metastore
#    environment:
#    - MYSQL_ROOT_PASSWORD=mysecret
#    ports:
#    - "13306:3306"
#    volumes:
#    - $PWD/container_data/mysql:/var/lib/mysql

  master:
    build: ./spark
    command: bash -c "/usr/sbin/sshd && bin/spark-class org.apache.spark.deploy.master.Master -h master"
    container_name: spark_master
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    links:
    - "hadoop:hadoop"
#    - "metastore:metastore"
    expose:
    - 7001
    - 7002
    - 7003
    - 7004
    - 7005
    - 7006
    - 7077
    - 6066
    - '22'
    ports:
    - 4040:4040
    - 6066:6066
    - 7077:7077
    - 18080:8080
    - 5005:5005 #For remote debug
    - '2222:22'
    volumes:
    - $PWD/spark/conf/master:/conf:z
    - $PWD/spark/classpath:/classpath:z
    - $PWD/container_data/spark/warehouse:/shared_data/hive/warehouse

  worker:
    build: ./spark
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    container_name: spark_worker
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    links:
    - master
    - "hadoop:hadoop"
    expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
    ports:
    - 8081:8081
    volumes:
    - $PWD/spark/conf/worker:/conf:z
    - $PWD/spark/classpath:/classpath:z
# TODO SCHEDULE A SPARK JOB https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/ch_oozie-spark-action.html
  oozie:
    build: ./oozie
    container_name: hadoop_oozie
    command: su oozie -c 'oozied.sh run'
    expose:
      - 11000
      - 11001
    # host:container
    ports:
      - 11000:11000
      - 11001:11001
    links:
      - hadoop
      - master

   # OLTP
  oltp:
    image: mysql
    container_name: mtnzcn_mysql
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    ports:
    - 1000:3306
    expose:
    - 1000
    environment:
      MYSQL_ROOT_PASSWORD: mypassword
    volumes:
      - /Users/miguelhalysortuno/Documents/Master/data:/var/lib/mysql
  adminer:
    image: adminer
    restart: always
    ports:
      - 8090:8080
    expose:
      - 8090

networks:
  default:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet:  192.168.104.1/16 # https://github.com/docker/compose/issues/4336